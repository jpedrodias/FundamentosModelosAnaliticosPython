{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d94696de",
   "metadata": {},
   "source": [
    "# Exercício 1 - Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701d28a6",
   "metadata": {},
   "source": [
    "Consideta o ficheiro train.csv, que contém o famoso dataset do Titanic, com informações de passageiros e se sobreviveram ou não. Eis um resumo completo:\n",
    "| Coluna       | Tipo    | Descrição                                                         |\n",
    "|--------------|---------|-------------------------------------------------------------------|\n",
    "| PassengerId  | int64   | Identificador único do passageiro                                 |\n",
    "| Survived     | int64   | Variável alvo: 1 = Sobreviveu, 0 = Não sobreviveu                 |\n",
    "| Pclass       | int64   | Classe do bilhete (1ª, 2ª, 3ª)                                    |\n",
    "| Name         | object  | Nome completo do passageiro                                       |\n",
    "| Sex          | object  | Sexo (masculino/feminino)                                         |\n",
    "| Age          | float64 | Idade                                                             |\n",
    "| SibSp        | int64   | Nº de irmãos/cônjuges a bordo                                     |\n",
    "| Parch        | int64   | Nº de pais/filhos a bordo                                         |\n",
    "| Ticket       | object  | Número do bilhete                                                 |\n",
    "| Fare         | float64 | Valor pago pelo bilhete                                           |\n",
    "| Cabin        | object  | Número da cabine (muitos valores em falta)                        |\n",
    "| Embarked     | object  | Porto de embarque: C = Cherbourg, Q = Queenstown, S = Southampton |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3b1f6b",
   "metadata": {},
   "source": [
    "Este dataset é ideal para aplicar classificação supervisionada, pois a variável Survived é binária (0 ou 1).\n",
    "\n",
    "\n",
    "No código seguinte fazemos:\n",
    "1. Pré-processamento\n",
    "1. Detecção de outliers\n",
    "1. Codificação\n",
    "1. Escalonamento\n",
    "1. Treino e avaliação do modelo com Random Forest\n",
    "1. Validação cruzada\n",
    "1. Ajuste de hiperparâmetros com GridSearchCV\n",
    "1. Testes adicionais: Curva ROC/AUC e comparação com Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08b69b3",
   "metadata": {},
   "source": [
    "Modelos aplicados:\n",
    "1. Random Forest Classifier\n",
    "    * É o modelo principal que está a ser treinado.\n",
    "    * É o modelo principal que está a ser treinado.\n",
    "    * Avaliado com: classification_report() (Precision, Recall, F1-score); confusion_matrix(); Validação cruzada StratifiedKFold; GridSearchCV para otimizar hiperparâmetros; Se binário: cálculo da Curva ROC e AUC\n",
    "1. Decision Tree Classifier\n",
    "    * Serve como modelo de comparação.\n",
    "    * Aplicado com profundidade máxima de 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78806ecf",
   "metadata": {},
   "source": [
    "# Classificação supervisionada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a1efd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdd0b542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeiras linhas do dataset:\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# 1, carregar o dataset\n",
    "df = pd.read_csv('data/titanic.csv')\n",
    "print('Primeiras linhas do dataset:')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06c0a250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumo estatístico:\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "\n",
      "Valores ausentes por coluna:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2. Exploração inicial\n",
    "print('\\nResumo estatístico:')\n",
    "print(df.describe())\n",
    "\n",
    "print('\\nValores ausentes por coluna:')\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45242f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Tratamento de valores ausentes (numéricos com mediana, categóricos com moda)\n",
    "num_cols = df.select_dtypes(include=np.number).columns\n",
    "cat_cols = df.select_dtypes(exclude='object').columns\n",
    "\n",
    "imputer_num = SimpleImputer(strategy='median')\n",
    "df[num_cols] = imputer_num.fit_transform(df[num_cols])\n",
    "\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "df[cat_cols] = imputer_cat.fit_transform(df[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f65c9b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Detecção de outliers com Z-Score e remoção\n",
    "from scipy.stats import zscore\n",
    "z_scores = np.abs(zscore(df[num_cols]))\n",
    "\n",
    "df = df[(z_scores < 3).all(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfd3465",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FormacaoModelos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
